{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    \n",
    "## Knowledge Recommendation Processing System\n",
    "    \n",
    "### Spelix Inc. R&D Center\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys,os\n",
    "\n",
    "tf.set_random_seed(777)\n",
    "\n",
    "def data_preprocessing(path='./inputdata/index_model.csv'):\n",
    "    \n",
    "    xy = np.loadtxt(path, delimiter=',', dtype=np.float32)\n",
    "    X_data = xy[:, 1:-1]\n",
    "    y_data2 = xy[:, [-1]]\n",
    "    y_data_temp,y_data=[],[]\n",
    "    \n",
    "    for i in range(len(y_data2)):\n",
    "        temp=[]\n",
    "        if y_data2[i][0] < 5: temp.append(y_data2[i][0])\n",
    "        else : temp.append(5)\n",
    "        y_data_temp.append(temp)\n",
    "\n",
    "    y_data = np.asarray(y_data_temp,dtype=np.float32)\n",
    "        \n",
    "    x_train_data, x_test,  y_train_data, y_test = train_test_split(X_data, y_data, test_size=0.2)\n",
    "    x_train, x_valid,  y_train, y_valid = train_test_split(x_train_data, y_train_data)\n",
    "    \n",
    "    nb_classes = len(np.unique(y_data))\n",
    "    x_colum = X_data.shape[1]\n",
    "    \n",
    "    return x_train,y_train,x_test,y_test,x_valid,y_valid,nb_classes,x_colum,X_data,y_data,y_data2\n",
    "\n",
    "def sigma(x):\n",
    "    # sigmoid function\n",
    "    # σ(x) = 1 / (1 + exp(-x))\n",
    "    return 1. / (1. + tf.exp(-x))\n",
    "\n",
    "def sigma_prime(x):\n",
    "    # derivative of the sigmoid function\n",
    "    # σ'(x) = σ(x) * (1 - σ(x))\n",
    "    return sigma(x) * (1. - sigma(x))\n",
    "\n",
    "def data_embedding(nb_classes,x_colum):\n",
    "    \n",
    "    X = tf.placeholder(tf.float32, [None, x_colum])\n",
    "    y = tf.placeholder(tf.int32, [None, 1])\n",
    "\n",
    "    target = tf.one_hot(y, nb_classes)\n",
    "    target = tf.reshape(target, [-1, nb_classes])\n",
    "    target = tf.cast(target, tf.float32)\n",
    "    \n",
    "    Y_one_hot = tf.one_hot(y, nb_classes)  \n",
    "    Y_one_hot = tf.reshape(Y_one_hot, [-1, nb_classes])\n",
    "    \n",
    "    return X, y, target,Y_one_hot\n",
    "\n",
    "def layer_structed(X, y, target, nb_classes, x_colum):\n",
    "    \n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "    \n",
    "    W1 = tf.get_variable(\"W1\", shape=[x_colum, x_colum],initializer=tf.contrib.layers.xavier_initializer())\n",
    "    b1 = tf.Variable(tf.random_normal([x_colum]), name='bias1')\n",
    "    l1 = tf.sigmoid(tf.matmul(X, W1) + b1)\n",
    "    l1 = tf.nn.dropout(l1, keep_prob=keep_prob)\n",
    "\n",
    "    W2 = tf.get_variable(\"W2\", shape=[x_colum, x_colum],initializer=tf.contrib.layers.xavier_initializer())\n",
    "    b2 = tf.Variable(tf.random_normal([x_colum]), name='bias2')\n",
    "    l2 = tf.sigmoid(tf.matmul(l1, W2) + b2)\n",
    "    l2 = tf.nn.dropout(l2, keep_prob=keep_prob)\n",
    "\n",
    "    W3 = tf.get_variable(\"W3\", shape=[x_colum, x_colum],initializer=tf.contrib.layers.xavier_initializer())\n",
    "    b3 = tf.Variable(tf.random_normal([x_colum]), name='bias3')\n",
    "    l3 = tf.sigmoid(tf.matmul(l2, W3) + b3)\n",
    "    l3 = tf.nn.dropout(l3, keep_prob=keep_prob)\n",
    "\n",
    "    W4 = tf.get_variable(\"W4\", shape=[x_colum, x_colum],initializer=tf.contrib.layers.xavier_initializer())\n",
    "    b4 = tf.Variable(tf.random_normal([x_colum]), name='bias4')\n",
    "    l4 = tf.sigmoid(tf.matmul(l3, W4) + b4)\n",
    "    l4 = tf.nn.dropout(l2, keep_prob=keep_prob)\n",
    "\n",
    "    W5 = tf.get_variable(\"W5\", shape=[x_colum, nb_classes],initializer=tf.contrib.layers.xavier_initializer())\n",
    "    b5 = tf.Variable(tf.random_normal([nb_classes]), name='bias5')\n",
    "    #     y_pred = tf.sigmoid(tf.matmul(l4, W5) + b5)\n",
    "    \n",
    "    # Forward propagtion\n",
    "    layer_5 = tf.matmul(X, W5) + b5\n",
    "    y_pred = sigma(layer_5)\n",
    "    \n",
    "    return W5, b5, layer_5, y_pred, keep_prob\n",
    "\n",
    "def loss_function(target,y_pred):\n",
    "    # Loss Function (end of forwad propagation)\n",
    "    loss_i = - target * tf.log(y_pred) - (1. - target) * tf.log(1. - y_pred)\n",
    "    loss = tf.reduce_mean(loss_i)\n",
    "    # Dimension Check\n",
    "    assert y_pred.shape.as_list() == target.shape.as_list()\n",
    "    return loss\n",
    "\n",
    "def optimizer(y_pred,target,layer_5,X):\n",
    "    # Back prop\n",
    "    d_loss = (y_pred - target) / (y_pred * (1. - y_pred) + 1e-7)\n",
    "    d_sigma = sigma_prime(layer_5)\n",
    "    d_b = d_loss * d_sigma #d_layer\n",
    "    d_W = tf.matmul(tf.transpose(X), d_b)\n",
    "    return d_b, d_W\n",
    "\n",
    "def pred_to_list(pred):\n",
    "    pred_list=[]\n",
    "    for i in range(len(pred)):\n",
    "        temp=[]\n",
    "        temp.append(pred[i])\n",
    "        pred_list.append(temp)\n",
    "    return pred_list\n",
    "\n",
    "def pred_by_restore(checkpoint_path, W5, b5, X, temp, y):\n",
    "    \n",
    "    predict_list=[]\n",
    "    \n",
    "    #hypothesis\n",
    "    hypothesis = tf.nn.sigmoid(tf.matmul(X, W5) + b5)\n",
    "    \n",
    "    #prediction\n",
    "    prediction = tf.argmax(hypothesis, 1) \n",
    "    \n",
    "    #sess\n",
    "    sess = tf.Session()\n",
    "    \n",
    "    #restore\n",
    "    saver = tf.train.Saver()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver.restore(sess, tf.train.latest_checkpoint(checkpoint_path))\n",
    "\n",
    "    pred = sess.run(prediction, feed_dict={ X : temp})\n",
    "    pred_list = sess.run(hypothesis,  feed_dict={ X: temp, y: pred_to_list(pred)}).tolist()\n",
    "\n",
    "    for i in range(len(pred_list)):\n",
    "        temp=[]\n",
    "        pred_list_sort, pred_list_index = sorted(pred_list[i],reverse=True),[]\n",
    "        \n",
    "        for j in range(len(pred_list[i])):\n",
    "            pred_list_index.append(pred_list[i].index(pred_list_sort[j]))\n",
    "            \n",
    "        temp.append(pred_list_sort)\n",
    "        temp.append(pred_list_index)\n",
    "        predict_list.append(temp)\n",
    "        \n",
    "    return predict_list\n",
    "\n",
    "def hyun(y,model_0,model_1,model_2,model_3,model_4):\n",
    "    \n",
    "    final_rank=[]\n",
    "    \n",
    "    for k in range(1):\n",
    "        k=400\n",
    "        final_rank_temp, final_temp=[], []\n",
    "        \n",
    "        model_index=[model_0[k][1],model_1[k][1],model_2[k][1],model_3[k][1],model_4[k][1]]\n",
    "        model_pers=[model_0[k][0],model_1[k][0],model_2[k][0],model_3[k][0],model_4[k][0]]\n",
    "        print(model_index)\n",
    "        print(model_pers)\n",
    "        \n",
    "        for i in range(len(model_index)):\n",
    "            if i != (len(model_index)-1):\n",
    "                for j in range(6):\n",
    "                    temp=[]\n",
    "                    if model_index[i][j] != 5:\n",
    "                        temp.append((i*5)+j)\n",
    "                        temp.append(model_pers[i][j])\n",
    "                        final_temp.append(temp)\n",
    "                    else:\n",
    "                        if i==0:rr=j\n",
    "                        break\n",
    "            else:\n",
    "                for j in range(6):\n",
    "                    temp=[]\n",
    "                    temp.append((i*5)+j)\n",
    "                    temp.append(model_pers[i][j])\n",
    "                    final_temp.append(temp)\n",
    "            print(final_temp)\n",
    "                \n",
    "        final_rank_temp.append(final_temp[0][0])\n",
    "        print(final_temp[0][0])\n",
    "        final_rank_temp.append(final_temp[:6])\n",
    "        print(final_temp[:6])\n",
    "        final_rank.append(final_rank_temp)\n",
    "    print(final_rank)\n",
    "    \n",
    "    return final_rank\n",
    "\n",
    "def hyun2(model_0,model_1,model_2,model_3,model_4):\n",
    "    model_list=[]\n",
    "    for i in range(len(model_0)):\n",
    "        model_list_temp=[]\n",
    "        frist_intserrup=0\n",
    "        for j0 in range(6):\n",
    "            if model_0[i][1][j0] == 5 :\n",
    "                frist_intserrup=j0\n",
    "                break\n",
    "            else :model_list_temp.append(model_0[i][1][j0])\n",
    "        for j1 in range(6):\n",
    "            if model_1[i][1][j1] == 5 :break\n",
    "            else :model_list_temp.append(model_1[i][1][j1]+5)\n",
    "        for j2 in range(6):\n",
    "            if model_2[i][1][j2] == 5 :break\n",
    "            else :model_list_temp.append(model_2[i][1][j2]+10)\n",
    "        for j3 in range(6):\n",
    "            if model_3[i][1][j3] == 5 :break\n",
    "            else :model_list_temp.append(model_3[i][1][j3]+15)\n",
    "        for j4 in range(6):\n",
    "            if model_4[i][0][j4] < 0.5 :\n",
    "                for j5 in range(6-len(model_list_temp)):\n",
    "                    try :\n",
    "                        model_list_temp.append(model_0[i][1][frist_intserrup+j5+1])\n",
    "                    except IndexError:\n",
    "                        pass\n",
    "            else : model_list_temp.append(model_4[i][1][j4]+20)\n",
    "        model_list_temp=model_list_temp[:6]\n",
    "        model_list.append(model_list_temp)\n",
    "    return model_list\n",
    "\n",
    "def save_csv(path,y_data,final_rank):\n",
    "    \n",
    "    pre_list=[]\n",
    "    bool_list=[]\n",
    "    \n",
    "    for i in range(len(final_rank)):\n",
    "        pre_list.append(final_rank[i])\n",
    "        bool_list.append(final_rank[i] == y_data.flatten()[i])\n",
    "\n",
    "    my_dict = {\"Y\": y_data.flatten(), \"Pre\": pre_list, \"c\": bool_list}\n",
    "    df = pd.DataFrame(my_dict)\n",
    "    \n",
    "    df.to_csv(path, encoding='euc-kr')\n",
    "    \n",
    "def save_csv2(path,y_data,final_rank):\n",
    "    \n",
    "    new_df = pd.DataFrame(columns=['rank_0', 'rank_1','rank_2','rank_3','rank_4','rank_5'],\n",
    "                          data=final_rank)\n",
    "    \n",
    "    y_data2=[]\n",
    "    for i in range(len(y_data)):\n",
    "        y_data2.append(y_data[i][0])\n",
    "    \n",
    "    new_df['real_Y'] = y_data2\n",
    "    \n",
    "    new_df['bool_result'] = (new_df['rank_0'] == new_df['real_Y']) | (new_df['rank_1'] == new_df['real_Y']) | (new_df['rank_2'] == new_df['real_Y']) | (new_df['rank_3'] == new_df['real_Y'])  | (new_df['rank_4'] == new_df['real_Y'])\n",
    "    \n",
    "    new_df.to_csv(path, encoding='euc-kr', index=False)\n",
    "    \n",
    "    return new_df\n",
    "\n",
    "def print_predict(df):\n",
    "    \n",
    "    a=len(df.bool_result)\n",
    "    b=len(df[df['bool_result']==True])\n",
    "    c=(int(b)/int(a))*100\n",
    "    t1,t2=[],[]\n",
    "    \n",
    "    for i in range(5):\n",
    "        t1.append(len(df[df['real_Y']==df[('rank_{0}'.format(i))]]))\n",
    "\n",
    "    for i in range(5):\n",
    "        t2.append((int(t1[i])/int(a))*100)\n",
    "              \n",
    "    print(\"result_count:\", a)\n",
    "    print(\"----------------------\")\n",
    "    print(\"result_ture_count:\", b)\n",
    "    print(\"----------------------\")\n",
    "    print(\"acc(%):\", c)\n",
    "              \n",
    "    for i in range(5):\n",
    "        print('-----------------------')\n",
    "        print('rank_{0}_acc : {1} %' .format(i,t2[i]))\n",
    "    \n",
    "def train(x_train,y_train,x_test,y_test,x_valid,y_valid,nb_classes,x_colum): #back_propagtion\n",
    "    \n",
    "    learning_rate = 0.0000005\n",
    "    global_step = 500001\n",
    "    valid_step = 10001\n",
    "    view_step = 5000\n",
    "    saver_step = 10000\n",
    "    \n",
    "    #data_embedding\n",
    "    X, y, target,Y_one_hot = data_embedding(nb_classes,x_colum)\n",
    "    \n",
    "    #layer_structed\n",
    "    W5, b5, layer_5, y_pred, keep_prob = layer_structed(X, y, target, nb_classes, x_colum)\n",
    "    \n",
    "    #loss_function\n",
    "    loss = loss_function(target,y_pred)\n",
    "\n",
    "    #optimizer\n",
    "    d_b, d_W = optimizer(y_pred, target, layer_5, X)\n",
    "    \n",
    "    # Train\n",
    "    # Updating network using gradients\n",
    "    train_step = [\n",
    "        tf.assign(W5, W5 - learning_rate * d_W),\n",
    "        tf.assign(b5, b5 - learning_rate * tf.reduce_sum(d_b)),]\n",
    "\n",
    "    # Prediction and Accuracy\n",
    "    prediction = tf.argmax(y_pred, 1)\n",
    "    acct_mat = tf.equal(tf.argmax(y_pred, 1), tf.argmax(target, 1))\n",
    "    acct_res = tf.reduce_mean(tf.cast(acct_mat, tf.float32))\n",
    "\n",
    "    saver = tf.train.Saver()\n",
    "    sess = tf.Session()\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    train_epoch=[[global_step, x_train, y_train],\n",
    "                [valid_step, x_valid, y_valid]]\n",
    "    \n",
    "    for i in range(len(train_epoch)) :\n",
    "        for step in range(train_epoch[i][0]):\n",
    "            sess.run(train_step, feed_dict={X: train_epoch[i][1], y: train_epoch[i][2], keep_prob: 0.6})\n",
    "\n",
    "            if step % view_step == 0:\n",
    "                step_loss, acc = sess.run([loss, acct_res], feed_dict={X:x_test, y:y_test})\n",
    "                print(\"Step: {:5}\\t Loss: {:10.5f}\\t Acc: {:.2%}\" .format(step, step_loss, acc))\n",
    "            if step % saver_step == 0:\n",
    "                saver.save(sess, './model_test/', global_step=step)\n",
    "\n",
    "    pred = sess.run(prediction, feed_dict={X: x_test, keep_prob: 1})\n",
    "\n",
    "def load(nb_classes,x_colum,X_data,y_data,y_data2,path):\n",
    "\n",
    "    #input_data\n",
    "    path='./input_data/index_model.csv'\n",
    "    xy = np.loadtxt(path, delimiter=',', dtype=np.float32)\n",
    "    xy2=xy[0].astype(np.int)\n",
    "    xy3=xy2[1:-1]\n",
    "    temp=''\n",
    "    for i in range(len(xy3)):\n",
    "        temp += (str(xy3[i])+',')\n",
    "    temp=temp[:-1]\n",
    "    temp2 = temp.split(\",\")\n",
    "    temp3 = np.array(temp2)\n",
    "    temp4 = temp3.astype(np.float32)\n",
    "    df_input = (pd.DataFrame(temp4)).T\n",
    "    \n",
    "    #data_embedding\n",
    "    X, y, target,Y_one_hot = data_embedding(nb_classes,x_colum)\n",
    "    \n",
    "    #layer_structed\n",
    "    W5, b5, layer_5, y_pred, keep_prob = layer_structed(X, y, target, nb_classes, x_colum)\n",
    "    \n",
    "    model_0 = pred_by_restore('./model/model_0',W5, b5, X, df_input,y)\n",
    "    model_1 = pred_by_restore('./model/model_1',W5, b5, X, df_input,y)\n",
    "    model_2 = pred_by_restore('./model/model_2',W5, b5, X, df_input,y)\n",
    "    model_3 = pred_by_restore('./model/model_3',W5, b5, X, df_input,y)\n",
    "    model_4 = pred_by_restore('./model/model_4',W5, b5, X, df_input,y)\n",
    "    \n",
    "    model_list = hyun2(model_0,model_1,model_2,model_3,model_4)\n",
    "    \n",
    "    return(model_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Pre_processing\n",
    "\n",
    "x_train,y_train,x_test,y_test,x_valid,y_valid,nb_classes,x_colum,X_data,y_data,y_data2=data_preprocessing(\n",
    "    path = './input_data/index_model.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Train\n",
    "\n",
    "# train(x_train,y_train,x_test,y_test,x_valid,y_valid,nb_classes,x_colum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Pre_Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Hyun\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-1-8d494a27e0a9>:63: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\Hyun\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ./model/model_0\\-10000\n",
      "INFO:tensorflow:Restoring parameters from ./model/model_1\\-10000\n",
      "INFO:tensorflow:Restoring parameters from ./model/model_2\\-10000\n",
      "INFO:tensorflow:Restoring parameters from ./model/model_3\\-10000\n",
      "INFO:tensorflow:Restoring parameters from ./model/model_4\\-10000\n",
      "[[0, 3, 23, 1, 4, 2]]\n"
     ]
    }
   ],
   "source": [
    "#Load\n",
    "\n",
    "new_df=load(nb_classes,x_colum,X_data,y_data,y_data2,\n",
    "     path='./predict_result/result.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "path='./input_data/index_model.csv'\n",
    "\n",
    "xy = np.loadtxt(path, delimiter=',', dtype=np.float32)\n",
    "\n",
    "type(xy[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "path='./input_data/index_model.csv'\n",
    "\n",
    "xy = np.loadtxt(path, delimiter=',', dtype=np.float32)\n",
    "xy2=xy[0].astype(np.int)\n",
    "xy3=xy2[1:-1]\n",
    "\n",
    "temp=''\n",
    "for i in range(len(xy3)):\n",
    "    temp += (str(xy3[i])+',')\n",
    "temp=temp[:-1]\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1434</th>\n",
       "      <th>1435</th>\n",
       "      <th>1436</th>\n",
       "      <th>1437</th>\n",
       "      <th>1438</th>\n",
       "      <th>1439</th>\n",
       "      <th>1440</th>\n",
       "      <th>1441</th>\n",
       "      <th>1442</th>\n",
       "      <th>1443</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 1444 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1     2     3     4     5     6     7     8     9     ...  1434  \\\n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0   0.0  ...   0.0   \n",
       "\n",
       "   1435  1436  1437  1438  1439  1440  1441  1442  1443  \n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[1 rows x 1444 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp2 = temp.split(\",\")\n",
    "temp3 = np.array(temp2)\n",
    "temp4 = temp3.astype(np.float32)\n",
    "df = (pd.DataFrame(temp4)).T\n",
    "df\n",
    "# temp4.to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = temp4[1:-1]\n",
    "y_data2 = [[-1]]\n",
    "y_data_temp,y_data=[],[]\n",
    "y_data2\n",
    "\n",
    "for i in range(len(y_data2)):\n",
    "    temp=[]\n",
    "    if y_data2[i][0] < 5: temp.append(y_data2[i][0])\n",
    "    else : temp.append(5)\n",
    "    y_data_temp.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "path='./input_data/index_model.csv'\n",
    "\n",
    "xy = np.loadtxt(path, delimiter=',', dtype=np.float32)\n",
    "\n",
    "\n",
    "X_data = xy[:, 1:-1]\n",
    "y_data2 = xy[:, [-1]]\n",
    "y_data_temp,y_data=[],[]\n",
    "\n",
    "for i in range(len(y_data2)):\n",
    "    temp=[]\n",
    "    if y_data2[i][0] < 5: temp.append(y_data2[i][0])\n",
    "    else : temp.append(5)\n",
    "    y_data_temp.append(temp)\n",
    "\n",
    "y_data = np.asarray(y_data_temp,dtype=np.float32)\n",
    "\n",
    "x_train_data, x_test,  y_train_data, y_test = train_test_split(X_data, y_data, test_size=0.2)\n",
    "x_train, x_valid,  y_train, y_valid = train_test_split(x_train_data, y_train_data)\n",
    "\n",
    "nb_classes = len(np.unique(y_data))\n",
    "x_colum = X_data.shape[1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1444"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_colum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(X_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=X_data[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=X_data[0].astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy=y.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " ...]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"./aaaaa.txt\", yy, newline=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'float32' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-f0894bdbbb8f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfloat32\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'float32' is not defined"
     ]
    }
   ],
   "source": [
    "float32"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
